# QLoRAå¾®è°ƒé¡¹ç›®ä»£ç å®¡æŸ¥æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäºQLoRAæŠ€æœ¯çš„è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒç³»ç»Ÿï¼Œæ•´ä½“ä»£ç æ¶æ„æ¸…æ™°ï¼Œæ¨¡å—åŒ–è®¾è®¡è‰¯å¥½ã€‚ä»£ç é‡‡ç”¨ä¸­æ–‡æ³¨é‡Šï¼Œç¬¦åˆé¡¹ç›®çš„æœ¬åœŸåŒ–è¦æ±‚ã€‚ç„¶è€Œï¼Œåœ¨å®‰å…¨æ€§ã€é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–å’Œä»£ç å¥å£®æ€§æ–¹é¢å­˜åœ¨ä¸€äº›éœ€è¦æ”¹è¿›çš„åœ°æ–¹ã€‚

**æ€»ä½“è¯„åˆ†ï¼š7.5/10**

- âœ… ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ¨¡å—åŒ–è®¾è®¡è‰¯å¥½
- âœ… ä¸­æ–‡æ³¨é‡Šè¯¦ç»†ï¼Œæ–‡æ¡£å®Œæ•´
- âœ… åŒ…å«å®Œæ•´çš„æµ‹è¯•éªŒè¯æµç¨‹
- âš ï¸ é”™è¯¯å¤„ç†æœºåˆ¶ä¸å¤Ÿå®Œå–„
- âš ï¸ å­˜åœ¨ä¸€äº›å®‰å…¨æ€§å’Œæ€§èƒ½é—®é¢˜
- âš ï¸ éƒ¨åˆ†é…ç½®ç¡¬ç¼–ç ï¼Œç¼ºä¹çµæ´»æ€§

## ä¼˜å…ˆçº§é—®é¢˜åˆ†ç±»

### ğŸ”´ Critical (P0) - å…³é”®é—®é¢˜

#### 1. å®‰å…¨æ¼æ´ï¼šæ–‡ä»¶ç¼–ç é—®é¢˜
**æ–‡ä»¶**: `requirements.txt`
**è¡Œæ•°**: 1-12
**é—®é¢˜**: requirements.txtæ–‡ä»¶ä½¿ç”¨äº†é”™è¯¯çš„ç¼–ç æ ¼å¼ï¼ŒåŒ…å«éASCIIå­—ç¬¦ï¼Œå¯èƒ½å¯¼è‡´å®‰è£…å¤±è´¥
```
å½“å‰å†…å®¹æ˜¾ç¤ºä¸ºä¹±ç ï¼šï¿½ï¿½t o r c h > = 2 . 0 . 0
```
**é£é™©**: ä¾èµ–åŒ…æ— æ³•æ­£ç¡®å®‰è£…ï¼Œå½±å“æ•´ä¸ªé¡¹ç›®çš„å¯ç”¨æ€§
**å»ºè®®**: é‡æ–°åˆ›å»ºrequirements.txtæ–‡ä»¶ï¼Œä½¿ç”¨UTF-8ç¼–ç 

#### 2. å®‰å…¨æ¼æ´ï¼šæœªéªŒè¯ç”¨æˆ·è¾“å…¥
**æ–‡ä»¶**: `train.py`
**è¡Œæ•°**: 141-144
**é—®é¢˜**: ç”¨æˆ·è¾“å…¥ç›´æ¥ä½¿ç”¨ï¼Œæœªè¿›è¡Œé€‚å½“çš„éªŒè¯å’Œæ¸…ç†
```python
response = input("\næ˜¯å¦å¼€å§‹è®­ç»ƒï¼Ÿ(y/N): ").strip().lower()
if response not in ['y', 'yes', 'æ˜¯']:
```
**é£é™©**: å¯èƒ½å­˜åœ¨æ³¨å…¥æ”»å‡»é£é™©
**å»ºè®®**: æ·»åŠ è¾“å…¥éªŒè¯å’Œæ¸…ç†æœºåˆ¶

#### 3. å…³é”®é”™è¯¯ï¼šæ¨¡å‹åç§°ç¡¬ç¼–ç ä¸ä¸€è‡´
**æ–‡ä»¶**: `model_config.py`
**è¡Œæ•°**: 21, 202, 223
**é—®é¢˜**: ä»£ç ä¸­ä½¿ç”¨äº†ä¸åŒçš„æ¨¡å‹åç§°ï¼Œå­˜åœ¨ä¸ä¸€è‡´æ€§
```python
# Line 21: google/gemma-3-4b-it
# Line 202: google/gemma-3-4b-it
# trainer.py Line 223: google/gemma-3-4b-it
```
**é£é™©**: å¯èƒ½å¯¼è‡´æ¨¡å‹åŠ è½½å¤±è´¥
**å»ºè®®**: ç»Ÿä¸€æ¨¡å‹åç§°ä¸ºæ­£ç¡®çš„ `google/gemma-2-9b-it`

### ğŸŸ  High (P1) - é«˜ä¼˜å…ˆçº§é—®é¢˜

#### 1. æ€§èƒ½é—®é¢˜ï¼šå†…å­˜ç®¡ç†ä¸å½“
**æ–‡ä»¶**: `trainer.py`
**è¡Œæ•°**: 160-164
**é—®é¢˜**: è¯„ä¼°æ¨¡å‹æ—¶é‡æ–°åŠ è½½å®Œæ•´æ¨¡å‹ï¼Œå ç”¨é¢å¤–å†…å­˜
```python
tokenizer = AutoTokenizer.from_pretrained(self.output_path)
model = AutoModelForCausalLM.from_pretrained(self.output_path)
```
**å½±å“**: å¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡ºï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§æ¨¡å‹è®­ç»ƒå
**å»ºè®®**: å¤ç”¨å·²è®­ç»ƒçš„æ¨¡å‹å®ä¾‹

#### 2. é”™è¯¯å¤„ç†ï¼šå¼‚å¸¸æ•è·è¿‡äºå®½æ³›
**æ–‡ä»¶**: `train.py`
**è¡Œæ•°**: 161-165
**é—®é¢˜**: ä½¿ç”¨ `except Exception as e` æ•è·æ‰€æœ‰å¼‚å¸¸
```python
except Exception as e:
    print(f"\nè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
```
**å½±å“**: éš¾ä»¥è°ƒè¯•ç‰¹å®šé”™è¯¯ï¼Œå¯èƒ½æ©ç›–é‡è¦é—®é¢˜
**å»ºè®®**: ä½¿ç”¨æ›´å…·ä½“çš„å¼‚å¸¸ç±»å‹

#### 3. æ¶æ„é—®é¢˜ï¼šå¾ªç¯å¯¼å…¥é£é™©
**æ–‡ä»¶**: `trainer.py`
**è¡Œæ•°**: 160-161
**é—®é¢˜**: åœ¨å‡½æ•°å†…éƒ¨å¯¼å…¥æ¨¡å—
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
```
**å½±å“**: å¯èƒ½å¯¼è‡´å¾ªç¯å¯¼å…¥ï¼Œå½±å“æ¨¡å—åŠ è½½æ€§èƒ½
**å»ºè®®**: å°†å¯¼å…¥ç§»åˆ°æ–‡ä»¶é¡¶éƒ¨

#### 4. æ•°æ®å®‰å…¨ï¼šéšæœºç§å­æœªè®¾ç½®
**æ–‡ä»¶**: `data_processor.py`
**è¡Œæ•°**: 43
**é—®é¢˜**: éšæœºé‡‡æ ·æ—¶æœªè®¾ç½®ç§å­
```python
sample_indices = random.sample(range(total_size), self.sample_size)
```
**å½±å“**: ç»“æœä¸å¯é‡ç°ï¼Œå½±å“å®éªŒçš„å¯é‡å¤æ€§
**å»ºè®®**: æ·»åŠ éšæœºç§å­è®¾ç½®

### ğŸŸ¡ Medium (P2) - ä¸­ç­‰ä¼˜å…ˆçº§é—®é¢˜

#### 1. ä»£ç è´¨é‡ï¼šé­”æ³•æ•°å­—é—®é¢˜
**æ–‡ä»¶**: `model_config.py`
**è¡Œæ•°**: 55-67
**é—®é¢˜**: é…ç½®å‚æ•°ç¡¬ç¼–ç 
```python
r=16,                    # LoRAç§©
lora_alpha=32,           # LoRAç¼©æ”¾å‚æ•°
lora_dropout=0.1,        # LoRA dropout
```
**å»ºè®®**: å°†è¿™äº›å‚æ•°æå–ä¸ºé…ç½®æ–‡ä»¶æˆ–ç±»å±æ€§

#### 2. é”™è¯¯å¤„ç†ï¼šèµ„æºæ¸…ç†ä¸å®Œæ•´
**æ–‡ä»¶**: `trainer.py`
**è¡Œæ•°**: 90-142
**é—®é¢˜**: è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œå¯èƒ½å¯¼è‡´èµ„æºæ³„éœ²
**å»ºè®®**: æ·»åŠ  try-finally å—ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾

#### 3. æ€§èƒ½ä¼˜åŒ–ï¼šåˆ†è¯æ•ˆç‡é—®é¢˜
**æ–‡ä»¶**: `trainer.py`
**è¡Œæ•°**: 76-88
**é—®é¢˜**: åˆ†è¯æ—¶ä½¿ç”¨å›ºå®šçš„max_length=512
```python
tokenized = tokenizer(
    examples["text"],
    truncation=True,
    padding='max_length',
    max_length=512,
```
**å»ºè®®**: æ ¹æ®æ•°æ®é›†åŠ¨æ€è°ƒæ•´max_lengthæˆ–è®¾ä¸ºå¯é…ç½®

#### 4. ä»£ç ç»“æ„ï¼šç±»èŒè´£è¿‡é‡
**æ–‡ä»¶**: `trainer.py`
**è¡Œæ•°**: 16-142
**é—®é¢˜**: QLoRATrainerç±»æ‰¿æ‹…äº†å¤ªå¤šèŒè´£ï¼ˆæ•°æ®å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°ï¼‰
**å»ºè®®**: æ‹†åˆ†ä¸ºæ›´å°çš„ä¸“èŒç±»

#### 5. æ—¥å¿—è®°å½•ä¸å®Œå–„
**æ–‡ä»¶**: æ‰€æœ‰Pythonæ–‡ä»¶
**é—®é¢˜**: ä½¿ç”¨printè¿›è¡Œæ—¥å¿—è¾“å‡ºï¼Œç¼ºä¹æ—¥å¿—çº§åˆ«æ§åˆ¶
**å»ºè®®**: ä½¿ç”¨Python loggingæ¨¡å—æ›¿ä»£printè¯­å¥

### ğŸŸ¢ Low (P3) - ä½ä¼˜å…ˆçº§é—®é¢˜

#### 1. æ–‡æ¡£æ”¹è¿›ï¼šç±»å‹æ³¨è§£ä¸å®Œæ•´
**æ–‡ä»¶**: `trainer.py`
**è¡Œæ•°**: 72, 107
**é—®é¢˜**: éƒ¨åˆ†å‡½æ•°ç¼ºä¹å®Œæ•´çš„ç±»å‹æ³¨è§£
```python
def setup_peft_model(self, model: Any) -> Any:  # Anyç±»å‹è¿‡äºå®½æ³›
```
**å»ºè®®**: ä½¿ç”¨æ›´å…·ä½“çš„ç±»å‹æ³¨è§£

#### 2. ä»£ç é£æ ¼ï¼šå‘½åçº¦å®šä¸ä¸€è‡´
**æ–‡ä»¶**: `data_processor.py`
**è¡Œæ•°**: 27, 50
**é—®é¢˜**: å‡½æ•°å‘½åé£æ ¼ä¸å®Œå…¨ä¸€è‡´
**å»ºè®®**: ç»Ÿä¸€ä½¿ç”¨åŠ¨è¯å¼€å¤´çš„å‡½æ•°å‘½å

#### 3. æ€§èƒ½ä¼˜åŒ–ï¼šå­—ç¬¦ä¸²æ‹¼æ¥æ•ˆç‡
**æ–‡ä»¶**: `data_processor.py`
**è¡Œæ•°**: 98-102
**é—®é¢˜**: ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥åˆ›å»ºprompt
**å»ºè®®**: ä½¿ç”¨f-stringæˆ–æ¨¡æ¿æ–¹æ³•

#### 4. æµ‹è¯•è¦†ç›–ï¼šè¾¹ç•Œæ¡ä»¶æµ‹è¯•ä¸è¶³
**æ–‡ä»¶**: `test_training.py`
**è¡Œæ•°**: 27
**é—®é¢˜**: æµ‹è¯•ç”¨ä¾‹ä½¿ç”¨çš„æ ·æœ¬æ•°é‡å¤ªå°(10æ¡)
**å»ºè®®**: å¢åŠ æ›´å¤šè¾¹ç•Œæ¡ä»¶æµ‹è¯•

## å…·ä½“æ”¹è¿›å»ºè®®

### 1. ç«‹å³ä¿®å¤ (P0)

```python
# ä¿®å¤ requirements.txt
torch>=2.0.0
transformers>=4.36.0
datasets>=2.14.0
peft>=0.7.0
bitsandbytes>=0.41.0
accelerate>=0.24.0
trl>=0.7.0
scipy
numpy
pandas
tqdm
```

```python
# ä¿®å¤ç”¨æˆ·è¾“å…¥éªŒè¯ (train.py)
import re

def validate_user_input(user_input: str) -> bool:
    """éªŒè¯ç”¨æˆ·è¾“å…¥çš„å®‰å…¨æ€§"""
    # åªå…è®¸ç‰¹å®šçš„å®‰å…¨å­—ç¬¦
    allowed_pattern = re.compile(r'^[yYnNæ˜¯å¦\s]*$')
    return bool(allowed_pattern.match(user_input))

response = input("\næ˜¯å¦å¼€å§‹è®­ç»ƒï¼Ÿ(y/N): ").strip().lower()
if not validate_user_input(response):
    print("æ— æ•ˆè¾“å…¥")
    sys.exit(1)
```

### 2. é«˜ä¼˜å…ˆçº§æ”¹è¿› (P1)

```python
# æ”¹è¿›å¼‚å¸¸å¤„ç† (train.py)
try:
    run_training(...)
except FileNotFoundError as e:
    print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    sys.exit(1)
except PermissionError as e:
    print(f"æƒé™é”™è¯¯: {e}")
    sys.exit(1)
except torch.cuda.OutOfMemoryError as e:
    print(f"GPUå†…å­˜ä¸è¶³: {e}")
    sys.exit(1)
except ImportError as e:
    print(f"ä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)
```

```python
# è®¾ç½®éšæœºç§å­ (data_processor.py)
import random
import numpy as np
import torch

def set_random_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
```

### 3. é…ç½®åŒ–æ”¹è¿›å»ºè®®

```python
# åˆ›å»ºé…ç½®æ–‡ä»¶ config.yaml
model:
  name: "google/gemma-2-9b-it"
  max_length: 512

lora:
  r: 16
  alpha: 32
  dropout: 0.1

training:
  epochs: 3
  batch_size: 1
  learning_rate: 2e-4

data:
  sample_size: 2000
  random_seed: 42
```

## æŠ€æœ¯å€ºåŠ¡è¯„ä¼°

| ç±»åˆ« | å½“å‰çŠ¶æ€ | ç›®æ ‡çŠ¶æ€ | å·¥ä½œé‡ä¼°è®¡ |
|------|----------|----------|------------|
| å®‰å…¨æ€§ | 6/10 | 9/10 | 2-3å¤© |
| é”™è¯¯å¤„ç† | 5/10 | 8/10 | 2-3å¤© |
| æ€§èƒ½ä¼˜åŒ– | 7/10 | 9/10 | 3-4å¤© |
| ä»£ç è´¨é‡ | 7/10 | 9/10 | 2-3å¤© |
| æµ‹è¯•è¦†ç›– | 6/10 | 8/10 | 3-5å¤© |

## åç»­è¡ŒåŠ¨å»ºè®®

1. **ç«‹å³è¡ŒåŠ¨**: ä¿®å¤requirements.txtæ–‡ä»¶ç¼–ç é—®é¢˜
2. **æœ¬å‘¨å†…**: å®ŒæˆP0å’ŒP1çº§åˆ«çš„å®‰å…¨æ€§å’Œé”™è¯¯å¤„ç†æ”¹è¿›
3. **ä¸‹å‘¨å†…**: å®æ–½é…ç½®åŒ–æ”¹è¿›å’Œæ€§èƒ½ä¼˜åŒ–
4. **æœ¬æœˆå†…**: å®Œå–„æµ‹è¯•è¦†ç›–å’Œä»£ç è´¨é‡æ”¹è¿›

## æ€»ç»“

è¯¥QLoRAå¾®è°ƒé¡¹ç›®å±•ç°äº†è‰¯å¥½çš„æ¶æ„è®¾è®¡å’Œæ¨¡å—åŒ–æ€ç»´ï¼Œä»£ç æ³¨é‡Šè¯¦ç»†ï¼Œæ–‡æ¡£å®Œæ•´ã€‚ä¸»è¦éœ€è¦å…³æ³¨çš„æ˜¯å®‰å…¨æ€§åŠ å›ºã€é”™è¯¯å¤„ç†å®Œå–„å’Œæ€§èƒ½ä¼˜åŒ–ã€‚å»ºè®®ä¼˜å…ˆå¤„ç†å…³é”®å®‰å…¨é—®é¢˜ï¼Œç„¶åé€æ­¥æ”¹è¿›ä»£ç è´¨é‡å’Œå¥å£®æ€§ã€‚æ•´ä½“è€Œè¨€ï¼Œè¿™æ˜¯ä¸€ä¸ªç»“æ„è‰¯å¥½ä½†éœ€è¦è¿›ä¸€æ­¥å®Œå–„çš„é¡¹ç›®ã€‚